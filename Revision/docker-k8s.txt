=====================DOCKER=======================
Container
A container is a lightweight, executable software unit that packages an application and all its dependencies, while sharing the host system’s kernel.
It runs as an isolated process using Linux kernel features like namespaces (isolation) and cgroups (resource control).
A container provides a consistent runtime environment regardless of where it’s deployed.
In simple terms: A container = an isolated process + its own filesystem, networking, and resources.

Docker
Docker is a platform and toolset for creating, distributing, and running containers.
It provides:
Build system → create images (docker build).
Image format & registry → standardized container images (e.g., Docker Hub).
Runtime & orchestration hooks → via containerd and runc.
Developer tooling → CLI and APIs to simplify working with containers.
Docker = the ecosystem that makes working with containers easy and practical.

🔄 Alternatives to Docker
Yes — containers are not tied to Docker. Docker just popularized them. Other tools can run containers:
Podman → Docker-compatible CLI, daemonless, rootless containers.
CRI-O → lightweight runtime, designed for Kubernetes.
containerd → high-level container runtime (Docker uses it under the hood).
runc → low-level runtime (actually spawns the container process).
LXC/LXD → older Linux containers system (basis of early Docker).
Kata Containers → containers with lightweight VMs for stronger isolation.

Container = the actual isolated environment/process.
Docker = the platform/tooling to build, run, and manage containers.
Alternatives = Podman, CRI-O, containerd, LXC, Kata Containers, etc.
==================================================================================
📊 Which Container Platform is Most Used in IT Industry Today

Docker (for development) → still the most widely used for building and running containers locally.
containerd (runtime) → the actual engine behind Docker; also adopted directly by Kubernetes.
Podman → popular in enterprises needing rootless/daemonless containers, but not as widespread as Docker.
CRI-O → used in Kubernetes environments (esp. Red Hat OpenShift).
Kubernetes itself → the dominant orchestration system; it doesn’t need Docker anymore (since v1.24), but relies on container runtimes like containerd or CRI-O.
Industry reality:
Docker is #1 for building images and dev workflows.
containerd & CRI-O are most used in production Kubernetes clusters.

Docker is famous because it simplified containerization and created a standard ecosystem.
Today, Docker dominates development, while in production Kubernetes clusters, the most common runtime is containerd, followed by CRI-O in Red Hat environments.
================================================================

Namespaces (Isolation)

Definition: Namespaces partition kernel resources so that one set of processes sees one set of resources, and another set sees a different set.
It’s like giving each container its own “view of the world.”

Main namespaces used in containers:
PID namespace → isolated process IDs (inside container, your process thinks it’s PID 1).
NET namespace → isolated network stack (own IP, routing, ports).
MNT namespace → isolated filesystem mounts (container sees only its rootfs, not host’s /).
UTS namespace → isolated hostname/domain name.
IPC namespace → isolated inter-process communication (shared memory, message queues).
USER namespace → isolated user/group IDs (map container’s root user to non-root host user).

 Effect: Inside a container, you only see your own processes, filesystem, and network — even though everything is running on the same Linux kernel.

 cgroups (Resource Control)

Definition: cgroups (control groups) limit and account for resources used by a group of processes.
Key controls:
CPU → how much CPU time the container can use.
MeMory → set memory limits; if exceeded, process gets killed (OOM).
Block I/O → control disk access speed.
PIDs → limit how many processes a container can spawn.

Effect: Prevents one container from hogging all system resources and ensures fair sharing across containers.

Putting It Together
Namespaces = “You only see your own world”  (isolation).
cgroups = “You only get your fair share” (resource control).
Together, they make a regular process look like it’s running in its own machine → that’s the essence of a container.

======================================================================

🐳 What Happens When You Run docker run?
Example:
docker run -d --name test alpine sleep 1000

⚙️ Step-by-Step Flow
1. CLI → Docker Daemon
The docker run command is sent from the Docker CLI → to the dockerd daemon (via REST API/Unix socket).
CLI is just a client — all real work happens in dockerd.

2. Image Resolution
Docker checks if the requested image (alpine) exists locally.
If not, it pulls from a registry (e.g., Docker Hub).
Images are stored in layers using a Union Filesystem (overlayfs).

3. Container Creation
dockerd asks containerd (a container runtime) to create the container.
containerd:
Creates container metadata.
Prepares root filesystem from the image.
Delegates to runc (low-level runtime).

4. runc: Setting Up the Container
This is where Linux kernel features come into play:
Create namespaces → PID, NET, MNT, IPC, UTS, USER.
Process thinks it’s in its own world.
Join cgroups → limit and track resources.
Mount root filesystem → rootfs from Alpine image mounted as /.
Configure networking → veth pairs, bridge, IP assignment.
Set hostname & environment.

5. Start the Process
Inside the prepared isolated environment, runc executes the specified command (sleep 1000).
From host’s perspective → it’s just a Linux process (sleep) with PID 22395.
From container’s perspective → it’s PID 1 in its own world.

6. containerd-shim
A lightweight process (containerd-shim-runc-v2) stays alive as the container’s parent.
Responsibilities:
Keeps container running even if dockerd crashes.
Handles logging.
Forwards signals between host & container.

7. Container Running
Now docker ps shows your container.
Inside it → you only see sleep 1000.
Outside it → it’s just another Linux process, but isolated via namespaces and controlled by cgroups.

🔄 Summary (Short Version)

Docker CLI → sends request to dockerd.
dockerd → delegates to containerd.
containerd → calls runc.
runc → sets up namespaces, cgroups, rootfs, networking.
The process (sleep 1000) runs in the isolated environment.
shim keeps it alive.
 Docker = a wrapper around Linux kernel isolation features, making them easy to use.

🔑 Does Docker Always Ask containerd?
Yes. Since Docker v1.11 (2016), Docker always goes through containerd.
containerd then uses runc (or another OCI runtime) to actually spawn the container.
Docker itself doesn’t talk to runc directly anymore.

🧩 Why containerd?
containerd is a container runtime daemon that handles:
Image unpacking
Filesystem snapshots
Container lifecycle (start, stop, delete)
Logging & monitoring
It was split out of Docker so it could be reused independently — e.g., by Kubernetes.

⚙️ The Runtime Stack
Docker CLI  →  dockerd  →  containerd  →  runc  →  Linux Kernel
Docker CLI → user interface.
dockerd → orchestrates, provides APIs.
containerd → manages containers & images.
runc → low-level runtime, calls kernel syscalls (clone() for namespaces, cgroups setup).
Linux Kernel → enforces isolation and resource limits.

✅ Final Takeaway
Running docker run = creating a normal Linux process, but wrapped inside namespaces (isolation) + cgroups (resource control).
Docker’s magic is making this simple for developers with CLI, images, and registry support.
=================================================================================================
Relationship between Docker/Container Runtime and Kubernetes
Containers need a runtime to exist
Docker Engine (historically), or now more commonly containerd or CRI-O, is the runtime that actually pulls images, creates containers, and manages their lifecycle.
Without a runtime, there are no containers.
Kubernetes needs a runtime to run workloads
Kubernetes does not run containers itself. It only tells the runtime: “I need a Pod with this container image, these resources, and these configs.”
The kubelet on each node talks to the runtime (via CRI) to make this happen.
They are loosely coupled
Kubernetes is the orchestrator (what to run, where, and how).
The container runtime is the executor (actually runs the container processes).
This loose coupling means Kubernetes is runtime-agnostic: you can swap Docker Engine with containerd or CRI-O, and Kubernetes will still work.
----------------------------------------------------------------------------------------------------------------

What do we mean by self-healing in Kubernetes?
“Self-healing” means that Kubernetes continuously ensures the actual cluster state matches the desired state you defined in your manifests.
If something goes wrong (a Pod crashes, a Node dies, a container is unhealthy), Kubernetes automatically fixes it without manual intervention.

How does Kubernetes implement self-healing?

Pod restart (CrashLoopBackOff → restart policy)
If a container inside a Pod crashes, the kubelet on that node restarts it according to the Pod’s restart policy (default is Always).
This is the most basic self-healing action.

Pod rescheduling (Node failure)
If a Node itself goes down or becomes unreachable, the control plane detects that Pods on that node are not running.
The Deployment/ReplicaSet ensures the desired number of replicas are maintained, so Kubernetes reschedules replacement Pods onto healthy nodes.

Replica management (ReplicaSets / Deployments)
If you declare replicas: 3 in a Deployment, Kubernetes constantly ensures that exactly 3 Pods are running.
If one dies, a new one is created automatically.
This maintains availability without manual restart.

Health checks (Probes)
Liveness probes: If a container is running but stuck (not responding), the kubelet kills and restarts it.
Readiness probes: If a container isn’t ready, Kubernetes removes it from Service endpoints until it passes the check again.
This avoids sending traffic to “zombie” Pods.

Controllers & Desired State Loop
The heart of self-healing is Kubernetes’ control loop:
User defines desired state → YAML manifests.
K8s continuously watches actual state → API server, etcd.
Controllers reconcile differences → take corrective action until they match.

----------------------------------------------------------------------------------------------------


Kubernetes Architecture – Who Does What?

Think of Kubernetes as a control plane + worker nodes system.

1. Control Plane (Brains of Kubernetes)
This is where orchestration logic lives.

API Server
The “front door” of the cluster.
All requests (from users, controllers, or kubelets) go through the API server.
Stores desired state in etcd.

etcd
Distributed key-value store.
Holds the desired state of the cluster (what you declared in YAML) and the actual state (reported by nodes).

Controller Manager
Runs controllers that constantly check cluster state and reconcile differences.
Example:
Deployment controller: ensures the correct number of Pods are running.
Node controller: reacts to node failures.

Scheduler
Decides where a Pod should run.
Looks at available nodes, resource requests (CPU, memory), affinity/taints, etc.

2. Worker Nodes (Where containers actually run)
These are the machines that run your app workloads.

kubelet
Agent running on every node.
Talks to the control plane (API server).
Ensures the containers described in PodSpecs are actually running via the container runtime.

Container Runtime (Docker Engine, containerd, CRI-O)
Pulls images and runs containers.
kubelet interacts with it through the CRI (Container Runtime Interface).

kube-proxy
Maintains networking rules so that Services and Pods can communicate (cluster networking).
Implements load-balancing for Services at the node level.

3. How Orchestration Actually Works (Step by Step)
Let’s say you apply a Deployment YAML (kubectl apply -f app.yaml):
API Server stores your desired state in etcd.
Deployment Controller sees that you want 3 Pods but none exist → it creates ReplicaSets → ReplicaSets create Pod specs.
Scheduler assigns each Pod to a suitable Node.
kubelet on each Node pulls the image and asks the container runtime (e.g., containerd) to start the container.
kube-proxy updates routing so traffic can reach the Pods through a Service.
Controllers continuously reconcile: if one Pod crashes, a new one is scheduled automatically.

Kubernetes orchestrates using a control plane (API server, etcd, scheduler, controller manager) that maintains desired state, and workers (kubelet, container runtime, kube-proxy) that enforce it. Controllers keep checking actual vs desired state, and kubelet executes container actions on nodes.

===============================================================================================================================================
